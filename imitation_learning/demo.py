#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Imitation Learning Demo
æ¨¡ä»¿å­¦ä¹ æ¼”ç¤ºè„šæœ¬

è¿™ä¸ªè„šæœ¬æä¾›äº†ä¸€ä¸ªå®Œæ•´çš„æ¨¡ä»¿å­¦ä¹ æµç¨‹æ¼”ç¤ºï¼Œ
ä»æ•°æ®æ”¶é›†åˆ°è®­ç»ƒå’Œè¯„ä¼°çš„å®Œæ•´ç¤ºä¾‹ã€‚
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def demo_data_collection():
    """æ¼”ç¤ºæ•°æ®æ”¶é›†"""
    print("ğŸ¯ Demo: Expert Data Collection")
    print("=" * 50)

    from data_collection import ImitationDataset

    # åˆ›å»ºæ•°æ®é›†ç®¡ç†å™¨
    dataset = ImitationDataset("demo_data")

    # æ”¶é›†å°‘é‡æ¼”ç¤ºæ•°æ®ç”¨äºæ¼”ç¤º
    print("ğŸ“š Collecting expert demonstrations...")
    trajectories = dataset.collect_expert_data(
        env_name='highway-v0',
        num_episodes=50,  # æ¼”ç¤ºç”¨å°‘é‡æ•°æ®
        max_steps=100
    )

    print(f"âœ… Collected {len(trajectories)} expert trajectories")

    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    stats = dataset.get_statistics()
    print(".2f")
    print(f"   Avg episode length: {stats['basic_stats']['avg_episode_length']:.1f}")
    print(".2f")
    print(f"   Action distribution: {stats['action_distribution']['action_probabilities']}")

    return trajectories


def demo_training(trajectories):
    """æ¼”ç¤ºæ¨¡å‹è®­ç»ƒ"""
    print("\nğŸ¯ Demo: Behavioral Cloning Training")
    print("=" * 50)

    from behavioral_cloning import BehavioralCloning
    from highway.highway_env import HighwayWrapper

    # åˆ›å»ºç¯å¢ƒåŒ…è£…å™¨
    env_wrapper = HighwayWrapper('highway-v0')
    state_dim = env_wrapper.get_state_dim()
    action_dim = env_wrapper.get_action_dim()

    print(f"ğŸ—ï¸  Creating BC model: {state_dim} states -> {action_dim} actions")

    # åˆ›å»ºè¡Œä¸ºå…‹éš†æ¨¡å‹
    bc_model = BehavioralCloning(
        state_dim=state_dim,
        action_dim=action_dim,
        hidden_dims=[128, 64],  # è¾ƒå°çš„ç½‘ç»œç”¨äºæ¼”ç¤º
        learning_rate=1e-3
    )

    # è®­ç»ƒæ¨¡å‹ï¼ˆå°‘é‡è½®æ•°ç”¨äºæ¼”ç¤ºï¼‰
    print("ğŸ“ Training model...")
    bc_model.train(
        trajectories=trajectories,
        env_wrapper=env_wrapper,
        batch_size=32,
        epochs=20,  # æ¼”ç¤ºç”¨å°‘é‡è½®æ•°
        validation_split=0.2
    )

    print(".4f")
    print(".3f")
    # ä¿å­˜æ¨¡å‹
    model_path = "demo_model.pth"
    bc_model.save_model(model_path)

    return bc_model, model_path


def demo_evaluation(bc_model, trajectories):
    """æ¼”ç¤ºæ¨¡å‹è¯„ä¼°"""
    print("\nğŸ¯ Demo: Model Evaluation")
    print("=" * 50)

    from behavioral_cloning import compare_with_expert

    # è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹
    print("ğŸ” Evaluating trained model...")
    eval_results = bc_model.evaluate(
        env_name='highway-v0',
        num_episodes=10,  # æ¼”ç¤ºç”¨å°‘é‡è¯„ä¼°
        max_steps=100,
        render=False
    )

    print(".2f"
    print(".2f"
    print(".1f"
    # ä¸ä¸“å®¶æ¯”è¾ƒ
    reward_gap, length_gap = compare_with_expert(trajectories, eval_results)

    print("ğŸ† Performance Analysis:")
    if abs(reward_gap) < 5:
        print("   âœ… BC performance is close to expert!")
    else:
        print("   âš ï¸  BC performance differs from expert (may need more training)")

    return eval_results


def demo_expert_vs_random():
    """æ¼”ç¤ºä¸“å®¶ç­–ç•¥ vs éšæœºç­–ç•¥"""
    print("\nğŸ¯ Demo: Expert vs Random Policy")
    print("=" * 50)

    from expert_policy import HighwayExpert
    from highway.highway_env import HighwayWrapper

    # åˆ›å»ºä¸“å®¶å’Œç¯å¢ƒ
    expert = HighwayExpert('highway-v0')
    env = HighwayWrapper('highway-v0')

    policies = {
        'Expert': lambda state: expert.get_action(state),
        'Random': lambda state: env.action_space.sample()
    }

    results = {}

    for name, policy in policies.items():
        print(f"ğŸ§ª Testing {name} policy...")

        episode_rewards = []
        for episode in range(5):  # å°‘é‡æµ‹è¯•
            state, info = env.reset()
            total_reward = 0
            steps = 0
            done = False

            while not done and steps < 50:
                action = policy(env.flatten_observation(state))
                state, reward, terminated, truncated, info = env.step(action)
                done = terminated or truncated
                total_reward += reward
                steps += 1

            episode_rewards.append(total_reward)

        results[name] = {
            'mean_reward': sum(episode_rewards) / len(episode_rewards),
            'episodes': len(episode_rewards)
        }
        print(".2f"
    env.close()

    # æ¯”è¾ƒç»“æœ
    expert_reward = results['Expert']['mean_reward']
    random_reward = results['Random']['mean_reward']
    improvement = expert_reward - random_reward

    print(".2f"
    return results


def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ Imitation Learning Demo")
    print("=" * 50)
    print("This demo will walk you through the complete imitation learning pipeline")
    print("including data collection, training, and evaluation.\n")

    try:
        # æ­¥éª¤1: æ•°æ®æ”¶é›†
        trajectories = demo_data_collection()

        # æ­¥éª¤2: æ¨¡å‹è®­ç»ƒ
        bc_model, model_path = demo_training(trajectories)

        # æ­¥éª¤3: æ¨¡å‹è¯„ä¼°
        eval_results = demo_evaluation(bc_model, trajectories)

        # æ­¥éª¤4: ä¸“å®¶ vs éšæœºç­–ç•¥å¯¹æ¯”
        comparison_results = demo_expert_vs_random()

        # æ€»ç»“
        print("\nğŸ‰ Demo Completed Successfully!")
        print("=" * 50)
        print("ğŸ“Š Summary:")
        print(f"   - Collected {len(trajectories)} expert trajectories")
        print(".4f"        print(".2f"        print(f"   - Model saved to: {model_path}")
        print("\nğŸš€ Next Steps:")
        print("   1. Try collecting more data: python data_collection.py --episodes 1000")
        print("   2. Train with full pipeline: python train_bc.py --epochs 100")
        print("   3. Evaluate your model: python evaluate_bc.py --model-path models/*/bc_model.pth")
        print("   4. Experiment with different environments and hyperparameters!")

        # æ¸…ç†æ¼”ç¤ºæ–‡ä»¶
        print("\nğŸ§¹ Cleaning up demo files...")
        import shutil
        if os.path.exists("demo_data"):
            shutil.rmtree("demo_data")
        if os.path.exists("demo_model.pth"):
            os.remove("demo_model.pth")
        print("âœ… Demo cleanup completed")

    except Exception as e:
        print(f"\nâŒ Demo failed: {e}")
        print("ğŸ’¡ Make sure all dependencies are installed:")
        print("   pip install -r requirements.txt")
        raise


if __name__ == "__main__":
    main()
